{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import nltk\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['figure.dpi'] = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Whoâ€™s Afraid of ChatGPT?\n",
    "\n",
    "## A Gentle Introduction to Text Analytics\n",
    "\n",
    "John Laudun  \n",
    "Department of English  \n",
    "University of Louisiana at Lafayette  \n",
    "johnlaudun@gmail.com  \n",
    "https://johnlaudun.net/  \n",
    "@johnlaudun@hcommons.social  \n",
    "\n",
    "All of today's materials, and this notebook, are available at: http://github.com/johnlaudun/workshop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Workshop Agenda\n",
    "\n",
    "1. Understanding what AI/ML are and how they are involved in text analytics\n",
    "2. Doing some \"analytics\" with a few texts\n",
    "3. Exploring the possibilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Focus on code as a form of inquiry \n",
    "## (*versus categorical thinking*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![Books and Research](images/books.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Artificial Intelligence, Machine Learning, & You\n",
    "\n",
    "- Machine learning used to be, and sometimes still is (in math departments) called **statistical learning**.\n",
    "- Most machine learning is a mix of statistical operations with **calculus** and **linear algebra**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### What that looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# our \"data\"\n",
    "x = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12])\n",
    "y = np.array([13, 14, 17, 12, 23, 24, 25, 25, 24, 28, 32, 33])\n",
    "\n",
    "# scatterplot\n",
    "plt.plot(x, y, 'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "m, b = np.polyfit(x, y, 1)\n",
    "plt.plot(x, y, 'o')\n",
    "plt.plot(x, m*x+b, color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(x, y, '-o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(x, m*x+b, color='red')\n",
    "plt.plot(x, y, '-o')\n",
    "plt.plot(6.5, 17, 'g*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "poly = np.polyfit(x, y, deg=5)\n",
    "plt.plot(x, y, 'o')\n",
    "plt.plot(np.polyval(poly, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"\"\" \\n\n",
    "y = {m:.2f} x  + {b:.2f}\\n\\n\\n\n",
    "versus \\n\\n\\n\n",
    "{np.poly1d(poly)}\\n \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The Math Involved\n",
    "\n",
    "- **Linear Algebra** to handle lots of \"dimensions\"\n",
    "- **Statistics** and **calculus** to determine possible relationships between the dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Dimensions?!\n",
    "\n",
    "```\n",
    "Text 1 = \"Mary had a little lamb whose fleece was white as snow.\"\n",
    "Text 2 = \"And everywhere that Mary went, the lamb was sure to go.\"\n",
    "\n",
    "t1 = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
    "t2 = [12, 13, 14, 1, 15, 16, 5, 8, 17, 18, 19]\n",
    "```\n",
    "\n",
    "But there are 12 lines: the resulting matrix for this poem would be ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# First we load our file into a string\n",
    "lamb = open('texts/marys-lamb.txt', 'r').read()\n",
    "\n",
    "# Then we turn that string into a list of words\n",
    "lamb_words = re.sub(\"[^a-zA-Z']\",\" \", lamb).lower().split()\n",
    "\n",
    "# Now let's determine the unique words & count them\n",
    "unique_words = set(lamb_words)\n",
    "print(f\"There are {len(unique_words)} unique words in this text.\\n\")\n",
    "print(f\"Those words are: {unique_words}.\\n\")\n",
    "print(f\"The matrix for this text would be 12 x 96.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Imagine a table 12 rows deep by 96 columns wide -- most scientific disciplines make each example, or observation, a row, and then they make each feature a column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "with open('texts/marys-lamb.txt', 'r') as the_file:\n",
    "    lines = the_file.readlines()\n",
    "\n",
    "vectors = vectorizer.fit_transform(lines)\n",
    "td = pd.DataFrame(vectors.todense())\n",
    "td.columns = vectorizer.get_feature_names_out()\n",
    "td.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "This is where linear algebra comes into play: we can pull the **term-document matrix** as this is called into two smaller matrices (factor it) in a way that, potentially, reveals key word clusters. (This is one form of *topic modeling*.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdm = td.T\n",
    "tdm['total_count'] = tdm.sum(axis=1)\n",
    "tdm = tdm.sort_values(by ='total_count', ascending=False)[:20]\n",
    "tdm['total_count'].plot.bar()\n",
    "# tdm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## But are all the words worth counting?"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
